{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1dc806a",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "- Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a0a76",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2423994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc485f",
   "metadata": {},
   "source": [
    "### Load the Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcb1411",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('titanic (1).csv')  # Replace 'path_to_titanic.csv' with the actual file path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becc1f68",
   "metadata": {},
   "source": [
    "### Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105ddae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Name,' 'Ticket,' and 'Cabin' columns\n",
    "titanic_data = titanic_data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc445b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (e.g., fill missing ages with the mean age)\n",
    "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace=True)\n",
    "titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2054ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables ('Sex' and 'Embarked')\n",
    "label_encoder = LabelEncoder()\n",
    "titanic_data['Sex'] = label_encoder.fit_transform(titanic_data['Sex'])\n",
    "titanic_data['Embarked'] = label_encoder.fit_transform(titanic_data['Embarked'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4859bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = titanic_data.drop('Survived', axis=1)  # Assuming 'Survived' is the target variable\n",
    "y = titanic_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5cb43df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9fa128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83d6f175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74a6cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64f9961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda54849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7597765363128491"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy = accuracy_score(y_test,y_pred)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5039122d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379560df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56580c9b",
   "metadata": {},
   "source": [
    "### Hyperparameter grid to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa962771",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features':[5,7,8,10],\n",
    "    'splitter':['best', 'random'],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ac13a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.77665715 0.76966414 0.77387964 0.78783611 0.7864572  0.79488821\n",
      " 0.77384024 0.80056141 0.79076135 0.78784596 0.79209101 0.7850389\n",
      " 0.81039102 0.79915296 0.81039102 0.79915296 0.79066286 0.7808628\n",
      " 0.75696838 0.79214025 0.76545849 0.79918251 0.75559933 0.79349946\n",
      " 0.76819659 0.7878755  0.78646705 0.78792475 0.7809022  0.79913326\n",
      " 0.80473752 0.80337831 0.80473752 0.80337831 0.80754457 0.7780459\n",
      " 0.75415148 0.7879149  0.76403034 0.81033192 0.76683739 0.80617551\n",
      " 0.77943465 0.7921698  0.7794445  0.77242194 0.76959519 0.80475721\n",
      " 0.79348961 0.80758397 0.79348961 0.80758397 0.79630651 0.80332907\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73738796 0.73458091 0.76402049 0.78227125 0.77101349 0.80055156\n",
      " 0.77387964 0.76683739 0.79494731 0.7864572  0.7892938  0.79766571\n",
      " 0.79210086 0.7921304  0.79210086 0.7921304  0.76676844 0.7907318\n",
      " 0.75140353 0.73315276 0.75987393 0.78794445 0.75140353 0.78650645\n",
      " 0.77383039 0.7893332  0.77244164 0.7851374  0.76824584 0.79628681\n",
      " 0.80901211 0.80478676 0.80901211 0.80478676 0.79070226 0.77241209\n",
      " 0.75138383 0.76267113 0.74577957 0.78504875 0.76545849 0.77805575\n",
      " 0.76402049 0.7808825  0.77246134 0.77525854 0.76543879 0.79631636\n",
      " 0.7836994  0.81178962 0.7836994  0.81178962 0.7879149  0.79769526\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74020487 0.73172461 0.76262189 0.77947405 0.77101349 0.80336846\n",
      " 0.77667684 0.76824584 0.79494731 0.78223185 0.7892938  0.79625726\n",
      " 0.79210086 0.7921304  0.79210086 0.7921304  0.76676844 0.7907318\n",
      " 0.75281198 0.73591057 0.76269083 0.78652615 0.75140353 0.78650645\n",
      " 0.77383039 0.7893135  0.77525854 0.78374865 0.76824584 0.79769526\n",
      " 0.80901211 0.80619521 0.80901211 0.80619521 0.79070226 0.77241209\n",
      " 0.75138383 0.74439082 0.74577957 0.77383039 0.76545849 0.77385994\n",
      " 0.76402049 0.78089235 0.77246134 0.76962474 0.76543879 0.79631636\n",
      " 0.7836994  0.81178962 0.7836994  0.81178962 0.7879149  0.79769526\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74020487 0.73172461 0.76262189 0.77947405 0.77101349 0.80336846\n",
      " 0.77667684 0.76824584 0.79494731 0.78223185 0.7892938  0.79625726\n",
      " 0.79210086 0.7921304  0.79210086 0.7921304  0.76676844 0.7907318\n",
      " 0.75281198 0.73591057 0.76269083 0.78652615 0.75140353 0.78650645\n",
      " 0.77383039 0.7893135  0.77525854 0.78374865 0.76824584 0.79769526\n",
      " 0.80901211 0.80619521 0.80901211 0.80619521 0.79070226 0.77241209\n",
      " 0.75138383 0.74439082 0.74577957 0.77383039 0.76545849 0.77245149\n",
      " 0.76402049 0.78089235 0.77246134 0.76962474 0.76543879 0.79631636\n",
      " 0.7836994  0.81178962 0.7836994  0.81178962 0.7879149  0.79769526\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74020487 0.73172461 0.76262189 0.77947405 0.77101349 0.80336846\n",
      " 0.77667684 0.76824584 0.79494731 0.78223185 0.7892938  0.79625726\n",
      " 0.79210086 0.7921304  0.79210086 0.7921304  0.76676844 0.7907318\n",
      " 0.75281198 0.73591057 0.76269083 0.78652615 0.75140353 0.78650645\n",
      " 0.77383039 0.7893135  0.77525854 0.78374865 0.76824584 0.79769526\n",
      " 0.80901211 0.80619521 0.80901211 0.80619521 0.79070226 0.77241209\n",
      " 0.75138383 0.74439082 0.74577957 0.77383039 0.76545849 0.77245149\n",
      " 0.76402049 0.78089235 0.77246134 0.76962474 0.76543879 0.79631636\n",
      " 0.7836994  0.81178962 0.7836994  0.81178962 0.7879149  0.79769526\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.79634591 0.79490791 0.79911356 0.80610657 0.78786566 0.79068256\n",
      " 0.785098   0.79633606 0.77384024 0.80897272 0.79634591 0.81461637\n",
      " 0.80468827 0.79492761 0.80468827 0.79492761 0.80761351 0.77945435\n",
      " 0.7822614  0.77816409 0.7823008  0.80613612 0.80471782 0.80758397\n",
      " 0.7780262  0.80054171 0.7907121  0.80613612 0.79770511 0.7893332\n",
      " 0.78928396 0.80478676 0.78928396 0.80478676 0.78508815 0.80898257\n",
      " 0.7823008  0.77108244 0.7823205  0.79907417 0.79349946 0.80332907\n",
      " 0.7808825  0.79633606 0.79074165 0.79490791 0.80196986 0.79632621\n",
      " 0.7808431  0.81037132 0.7808431  0.81037132 0.77943465 0.7907515\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74997538 0.74865557 0.75703733 0.78223185 0.77669654 0.78652615\n",
      " 0.78366    0.7907318  0.77805575 0.79490791 0.77945435 0.79203191\n",
      " 0.78926426 0.77803605 0.78926426 0.77803605 0.78512755 0.78225155\n",
      " 0.75840638 0.74999508 0.76686694 0.78504875 0.77101349 0.77244164\n",
      " 0.74713878 0.79489806 0.76115434 0.7836797  0.76405003 0.77661775\n",
      " 0.77243179 0.79916281 0.77243179 0.79916281 0.77951344 0.78370925\n",
      " 0.74997538 0.74020487 0.75559933 0.7850783  0.7808628  0.80338816\n",
      " 0.75564858 0.77943465 0.75705703 0.78790505 0.77247119 0.78089235\n",
      " 0.76821629 0.81036147 0.76821629 0.81036147 0.76680784 0.79632621\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74997538 0.74019502 0.75562888 0.7723727  0.77247119 0.7879346\n",
      " 0.78366    0.785098   0.77805575 0.79773466 0.77945435 0.79203191\n",
      " 0.78926426 0.77803605 0.78926426 0.77803605 0.78512755 0.78225155\n",
      " 0.75561903 0.75557963 0.76404019 0.76964444 0.76820644 0.77524869\n",
      " 0.74995568 0.79068256 0.75833744 0.7822811  0.76545849 0.7808431\n",
      " 0.77243179 0.79916281 0.77243179 0.79916281 0.77951344 0.78370925\n",
      " 0.74997538 0.73738796 0.75559933 0.7893135  0.7808628  0.79777406\n",
      " 0.75564858 0.77104304 0.75987393 0.78930365 0.77247119 0.78229095\n",
      " 0.76962474 0.81036147 0.76962474 0.81036147 0.76680784 0.79632621\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74997538 0.74019502 0.75562888 0.7723727  0.77247119 0.78370925\n",
      " 0.78366    0.785098   0.77805575 0.79773466 0.77945435 0.79203191\n",
      " 0.78926426 0.77803605 0.78926426 0.77803605 0.78512755 0.78225155\n",
      " 0.75421058 0.75557963 0.76404019 0.76964444 0.76820644 0.77524869\n",
      " 0.74995568 0.79068256 0.75833744 0.7822811  0.76545849 0.7808431\n",
      " 0.77243179 0.79916281 0.77243179 0.79916281 0.77951344 0.78370925\n",
      " 0.74997538 0.73738796 0.75559933 0.7893135  0.7808628  0.79777406\n",
      " 0.75564858 0.77104304 0.75987393 0.78930365 0.77247119 0.78229095\n",
      " 0.76962474 0.81036147 0.76962474 0.81036147 0.76680784 0.79632621\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74997538 0.74019502 0.75562888 0.7723727  0.77247119 0.78370925\n",
      " 0.78366    0.785098   0.77805575 0.79773466 0.77945435 0.79203191\n",
      " 0.78926426 0.77803605 0.78926426 0.77803605 0.78512755 0.78225155\n",
      " 0.75421058 0.75557963 0.76404019 0.76964444 0.76820644 0.77524869\n",
      " 0.74995568 0.79068256 0.75833744 0.7822811  0.76545849 0.7808431\n",
      " 0.77243179 0.79916281 0.77243179 0.79916281 0.77951344 0.78370925\n",
      " 0.74997538 0.73738796 0.75559933 0.7893135  0.7808628  0.79777406\n",
      " 0.75564858 0.77104304 0.75987393 0.78930365 0.77247119 0.78229095\n",
      " 0.76962474 0.81036147 0.76962474 0.81036147 0.76680784 0.79632621\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 20, 30, 40, 50],\n",
       "                         'max_features': [5, 7, 8, 10],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Grid Search with cross-validation (e.g., K=5)\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd1ab357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 10,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0176dfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=10, max_features=5,\n",
       "                       min_samples_leaf=2, min_samples_split=10,\n",
       "                       random_state=42, splitter='random')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Decision Tree classifier with the best hyperparameters\n",
    "best_clf = DecisionTreeClassifier(random_state=42, **best_params)\n",
    "best_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40c44084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156424581005587"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred = best_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad2b5614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'random'}\n",
      "Model Accuracy on Test Data: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters and model accuracy\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Model Accuracy on Test Data: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8dc1df7",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "C: Inverse of regularization strength (smaller values mean stronger regularization).\n",
    "penalty: The norm used in the penalization ('l1', 'l2', 'elasticnet').\n",
    "solver: Algorithm to use for optimization ('liblinear', 'saga', 'lbfgs').\n",
    "\n",
    "2. Support Vector Machines (SVC)\n",
    "C: Regularization parameter (larger values make the decision boundary more strict).\n",
    "kernel: Specifies the kernel type ('linear', 'poly', 'rbf', 'sigmoid').\n",
    "degree: Degree of the polynomial kernel (used with 'poly' kernel).\n",
    "gamma: Kernel coefficient for 'rbf', 'poly', and 'sigmoid' kernels.\n",
    "\n",
    "3. K-Nearest Neighbors (KNN)\n",
    "n_neighbors: Number of neighbors to consider (e.g., 3-15).\n",
    "weights: Weight function used ('uniform', 'distance').\n",
    "p: Power parameter for the Minkowski distance (1: Manhattan, 2: Euclidean).\n",
    "\n",
    "4. Random Forest Classifier\n",
    "n_estimators: Number of trees in the forest.\n",
    "max_depth: Maximum depth of each tree.\n",
    "min_samples_split: Minimum samples required to split an internal node.\n",
    "min_samples_leaf: Minimum number of samples required at a leaf node.\n",
    "max_features: Number of features to consider for the best split.\n",
    "\n",
    "5. Gradient Boosting Classifier (e.g., XGBoost, LightGBM, CatBoost)\n",
    "n_estimators: Number of boosting rounds.\n",
    "learning_rate: Shrinks the contribution of each tree.\n",
    "max_depth: Maximum depth of each tree.\n",
    "subsample: Fraction of samples to use for each tree.\n",
    "colsample_bytree: Fraction of features to sample for each tree.\n",
    "gamma: Minimum loss reduction required to make a further split in a tree (XGBoost-specific).\n",
    "\n",
    "6. Neural Networks (MLPClassifier)\n",
    "hidden_layer_sizes: Number of neurons in each hidden layer.\n",
    "activation: Activation function ('identity', 'logistic', 'tanh', 'relu').\n",
    "solver: The algorithm for optimization ('lbfgs', 'sgd', 'adam').\n",
    "alpha: L2 penalty (regularization term).\n",
    "learning_rate_init: Initial learning rate.\n",
    "\n",
    "7. Logistic Regression Variants\n",
    "For regularized variants like Ridge Classifier or Lasso Classifier:\n",
    "alpha: Regularization strength (like Ridge/Lasso in regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4c58d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
